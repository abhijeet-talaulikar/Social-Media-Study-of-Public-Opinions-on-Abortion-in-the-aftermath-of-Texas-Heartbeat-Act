{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import ast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_itemsets(transaction_db, min_sup):\n",
    "    \n",
    "    items = {}\n",
    "    \n",
    "    for t_tup in transaction_db.list_items:\n",
    "        \n",
    "        # Remove duplicates in list.\n",
    "        # This is required because a transaction might have multiple occurences of an item.\n",
    "        # We are not using occurence information in the vanilla algorithm.\n",
    "        new_t = []\n",
    "        [new_t.append(x) for x in t_tup[0] if x not in new_t]\n",
    "        \n",
    "        for i in new_t:\n",
    "            if i in items.keys():\n",
    "                items[i] += t_tup[1]\n",
    "            else:\n",
    "                items[i] = t_tup[1]\n",
    "    \n",
    "    # Eliminate one itemsets which do not meet minimum support criteria\n",
    "    items = {i:sup for (i,sup) in items.items() if sup >= min_sup}\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_transaction(t, one_itemset_dict):\n",
    "    sorted_t = sorted(one_itemset_dict.keys(), key=one_itemset_dict.get, reverse=True)\n",
    "    return [i for i in sorted_t if i in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87497dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_contains_node(name, parent, fp_tree):\n",
    "    for node in fp_tree:\n",
    "        if (node['name'] == name) and (node['parent'] is parent):\n",
    "            return node\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tree(prefix, suffix, current_root, fp_tree, node_link_dict, transaction_count):\n",
    "    \n",
    "    # Check if route to the prefix node exists in tree\n",
    "    # If exists, get the node\n",
    "    new_root = tree_contains_node(prefix, current_root, fp_tree)\n",
    "    \n",
    "    if new_root == False:\n",
    "        # If route doesn't exist, create new child node to current root\n",
    "        new_root = {'name':prefix, 'count':transaction_count, 'parent': current_root}\n",
    "        \n",
    "        # Add the link to node link dictionary\n",
    "        node_link_dict[prefix].append(new_root)\n",
    "        \n",
    "        # Add new node to tree\n",
    "        fp_tree.append(new_root)\n",
    "    else:\n",
    "        # If route exists, increase its count by 1\n",
    "        new_root['count'] += transaction_count\n",
    "    \n",
    "    # If reached the end of transaction, stop\n",
    "    if len(suffix) == 0:\n",
    "        return\n",
    "    \n",
    "    # Recursively call itself\n",
    "    insert_tree(suffix[0], suffix[1:], new_root, fp_tree, node_link_dict, transaction_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c13e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_growth(transaction_db, min_sup, fp_list, prefix = [], output=True):\n",
    "    \n",
    "    ####### PART A: GENERATE FREQUENT PATTERNS AND SORT TRANSACTIONS #######\n",
    "    \n",
    "    # Get one itemsets which meet minimum support\n",
    "    one_itemset_dict = get_one_itemsets(transaction_db, min_sup)\n",
    "    \n",
    "    # Concanenate frequent patterns with prefix\n",
    "    freq_patterns = []\n",
    "    for key,val in one_itemset_dict.items():\n",
    "        pattern = prefix + [key]\n",
    "        freq_patterns.append((pattern,val))\n",
    "    \n",
    "    if output:\n",
    "        fp_list.append(freq_patterns)\n",
    "    else:\n",
    "        for pat in freq_patterns:\n",
    "            if pat not in fp_list:\n",
    "                fp_list.append(pat[0])\n",
    "    \n",
    "    if output:\n",
    "        print(\"\\n\\nFrequent patterns generated: \", freq_patterns)\n",
    "    \n",
    "    # Sort items within transactions in descending order and eliminate\n",
    "\n",
    "    if output:\n",
    "        print(f\"\\n\\nCurrent Pattern base for prefix {prefix}: \", end='')\n",
    "        display(transaction_db)\n",
    "\n",
    "    # Initialize node link dictionary\n",
    "    # This will store node links to each item in tree\n",
    "    node_link_dict = {item:[] for item in one_itemset_dict.keys()}\n",
    "\n",
    "    # Create tree data structure as a list of dictionary nodes\n",
    "    # Each node is {name: item-name, count: count, parent: parent-node}\n",
    "    # Insert root node as {name:None, count:None, parent: None}\n",
    "    # The traversal count will be used in Part C (mining the tree)\n",
    "    fp_tree = [{'name':\"Root\", 'count':None, 'parent': None}]\n",
    "    \n",
    "    \n",
    "    ####### PART B: GENERATE FP TREE #######\n",
    "    \n",
    "    # Generate FP tree by scanning over all sorted transactions\n",
    "    root_node = fp_tree[0]\n",
    "    for t_tup in transaction_db.list_items:\n",
    "        \n",
    "        # Sort t according to 1-itemset support counts\n",
    "        # This is required only at the root node\n",
    "        if prefix == []:\n",
    "            t = sort_transaction(t_tup[0], one_itemset_dict)\n",
    "        else:\n",
    "            t = [i for i in t_tup[0] if i in one_itemset_dict.keys()]\n",
    "        \n",
    "        if len(t) > 1:\n",
    "            insert_tree(t[0], t[1:], root_node, fp_tree, node_link_dict, t_tup[1])\n",
    "\n",
    "    if output:\n",
    "        print(f\"\\n\\nGenerated FP-Tree for prefix {prefix}: \\n\")\n",
    "        print_fp_tree(fp_tree)\n",
    "    \n",
    "    \n",
    "    ####### PART C: GENERATE CONDITIONAL PATTERN BASE #######\n",
    "    \n",
    "    for item in one_itemset_dict.keys():\n",
    "        \n",
    "        cpb_transactions = []\n",
    "        cond_pattern_base = []\n",
    "        \n",
    "        # Iterate over all node links of item\n",
    "        for node in node_link_dict[item]:\n",
    "\n",
    "            cur_node = node['parent']\n",
    "            cur_route = []\n",
    "\n",
    "            if cur_node is root_node:\n",
    "                continue\n",
    "\n",
    "            while cur_node is not root_node:\n",
    "                cur_route.insert(0, cur_node)\n",
    "                cur_node = cur_node['parent']\n",
    "\n",
    "            cond_pattern_base.append((cur_route, node['count']))\n",
    "            \n",
    "            cpb_transactions.append(([path['name'] for path in cur_route], node['count']))\n",
    "        \n",
    "        if len(cond_pattern_base) > 0:\n",
    "            if output:\n",
    "                print(f\"\\n\\nCPB for {item}: \", end='')\n",
    "                print_cpb(cond_pattern_base)\n",
    "        \n",
    "        \n",
    "        ####### PART D: RECURSE ON CONDITIONAL PATTERN BASE #######\n",
    "        \n",
    "        cpb_db = pd.DataFrame({'list_items':cpb_transactions})\n",
    "        \n",
    "        if cpb_db.shape[0] > 0:\n",
    "            fp_growth(cpb_db, min_sup, fp_list, prefix + [item], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('withtexas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions=[]\n",
    "for _,row in data.iterrows():\n",
    "    t = []\n",
    "    t.append(row['gender'])\n",
    "    t.append(row['age'])\n",
    "    #t.append(row['org'])\n",
    "    if not str(row['race'])=='nan':\n",
    "        t.append(row['race'])\n",
    "    if row['texas']==1:\n",
    "        t.append('texas')\n",
    "    transactions.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e16567",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf=pd.DataFrame({'list_items':transactions})\n",
    "tdf['list_items'] = tdf['list_items'].apply(lambda x: (x,1))\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2615ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store frequent patterns\n",
    "frequent_patterns = []\n",
    "\n",
    "# Minimum support threshold\n",
    "min_sup = 0.08 * tdf.shape[0]\n",
    "\n",
    "start_t = time.perf_counter()\n",
    "\n",
    "# Run FP growth\n",
    "fp_growth(tdf, min_sup, frequent_patterns, output=False)\n",
    "\n",
    "end_t = time.perf_counter()\n",
    "\n",
    "print(f\"Running time of FP-Growth = {end_t - start_t} seconds\")\n",
    "\n",
    "print(f\"Number of frequent patterns generated by FP-Growth = {len(frequent_patterns)}\\n\")\n",
    "frequent_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e8ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
